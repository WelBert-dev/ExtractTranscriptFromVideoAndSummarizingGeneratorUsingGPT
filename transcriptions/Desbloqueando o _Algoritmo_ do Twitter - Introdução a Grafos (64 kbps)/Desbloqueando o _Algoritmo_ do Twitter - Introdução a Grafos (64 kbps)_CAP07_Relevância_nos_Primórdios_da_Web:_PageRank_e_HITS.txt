 Um exemplo de grafo que eu não mencionei, mas deveria ser óbvio, é a própria World Wide Web. Toda página na internet é um nó. As bordas vertas são linkas de uma página pra outra e no começo da web já se tinha um número grande de páginas, o suficiente pra se difícil de achar as coisas. Pense numa era antes de existir Google e a forma rudimentar que existia pra gente se achar era derivado do conceito antiquado de páginas amarelas. Se você for muito novo, talvez nunca tenha visto, mas antigamente, quando precisávamos achar um mecânico, um médico, qualquer serviço, tínhamos um livrão físico de páginas amarelas que era um diretório com todo o serviço da cidade. Cada cidade tinha um livro diferente. Imagine que novos negócios tinham dificuldade de ser encontrados porque precisava esperar uma nova edição sem pressa e distribuída pra todo mundo. Páginas de classificados nos jornais meio que cobriam um pouco essa diferença. Serviços como Yahoo, Excite, Laicos e outros serviam esse papel na web. Se eu criasse um site novo, pedia pra ser incluído num desses diretórios pra que as pessoas conseguissem me achar. Esse era o processo. Mas mesmo assim, imagine em restaurantes. Qual das centenas de restaurantes numa cidade grande como São Paulo seria relevante pra mim? Mesmo se tivesse a opção de filtrar por localização e tipo de cozinha, ainda assim eu tinha que manualmente tentar várias. Era bem trabalhoso. Portanto, resolver esse problema de relevância entre milhares de partes nas web era muito importante. E lá no meio por fim dos anos 90 surgiram pelo menos dois estilos diferentes de lidar com isso. A maioria de vocês que estudou o mínimo de grafos talvez esteja familiarizado com o famoso Paper de PageRank, literalmente ranking de páginas inventado pelos fundadores do Google Larry Page e Sergey Brin em 1996 quando ainda eram estudantes de Stanford. Procurem no YouTube. Tem dezenas de vídeos que explicam PageRank, mas a ideia básica é a seguinte. Começa pelo básico. O H de HTML é pra hyperlink. Todo mundo esquece isso, mas o mais importante numa página web é que a página de alguém contém o link pra sua página. Com mais sites diferentes tem links apontando pro seu site, mais relevante ele pode ser. No PageRank imaginamos um navegador aleatório, uma pessoa imaginária que vai clicando em páginas e nos links nessas páginas aleatoriamente. Qual a probabilidade de só navegando sem rumo alguém cair na sua página? Essa probabilidade é o seu score, sua pontuação. Se sua página é famosa, centenas de outras páginas contem links pra sua. A probabilidade desse navegador aleatório chegar na sua página é alta, portanto sua pontuação no ranking do PageRank é alta. Esse foi o algoritmo usado na primeira versão do Google, o site que matou todos os diretórios estilo páginas amarelas. Porque agora era possível fazer um programa que sai vasculhando todas as páginas da web, avaliando os hyperlinks entre eles e atribuindo pontuações nesse ranking. Daí quando fazemos uma pesquisa ele nos mostra primeiro as páginas mais bem pontuadas. É por isso que logo na primeira página os primeiros links costumam ser os mais corretos. Com isso eliminamos a necessidade de seres humanos ficarem manualmente classificando páginas em diretórios e atualizando a relevância na mão, que sempre foi demorado, trabalhoso, tedioso e com muita margem de erro. Essa talvez tenha sido a primeira categoria de trabalhadores da web que perderam seu trabalho pra um algoritmo e não será a última. Tudo que é feito manualmente e pode ser automatizado certamente será. Todo trabalho repetitivo é automatizável, sabemos isso desde o começo da web. Mas todo o algoritmo tem seu ponto fraco e rapidamente as pessoas começaram a notar que se o lance é esse número de links pra sua página, que tal criar um monte de sites fantasma que fazem links pra uma página que você quer tornar relevante. E assim surgindo os primeiros web farms, fazendas de servidores fake, e uma galera que vendia relevância pro seu site fazendo um monte de site falso linkar pra sua, seja criando sites besta em série ou invadindo sites dos outros pra colocar links. Isso aconteceu só lá no começo dos anos 2000, por isso o Google evoluiu e deixou de usar page rank e passou a usar por exemplo trust rank, que combate web spam identificando quem é site legítimo e quem não é e descontando pontuação. Ao longo dos anos, o Google sempre foi aprimorando esses algoritmos, não é um produto fixo. O limite do trabalho de agências web era ficar monitorando quando o Google lançava uma nova versão pra modificar as estratégias pra levar relevância pros seus clientes. Esses truques baratos não funcionam mais hoje. Mas não era só isso, mesmo sem spammer e gente maliciosa, as primeiras versões do page rank ainda sofriam de um problema grave. Pra ilustrar, veja meu conteúdo, meu canal e meu blog, que é de um domínio muito específico de assuntos de tecnologia pra programadores. Talvez eu faça um vídeo explicando em detalhes sobre o algoritmo do Twitter, exatamente o que eu tô fazendo agora. Pra programadores é relevante. Porém, imagine que um bosta como um Felipe Neto também faça um vídeo falando sobre o algoritmo do Twitter. Segundo o page rank, que é um ranking global, quer você goste dele ou não se pesquisar no Google de 1997, algoritmo do Twitter, esse vídeo do Felipe Neto iria aparecer na frente do meu. Mas a sua é a desvantagem de um algoritmo de ranking global como o page rank original. Mas como eu falei, as pesquisas em torno de grafos evoluíram rápido. Por exemplo, em 1999 surgiu o algoritmo hits, que significa hyperlink em dúcia de topic search de John Kleinberg. E hits opera num grafo direcionado onde páginas web representam nós e hyperlinks são bordas direcionadas. E até aqui igual o page rank. Mas o hits assinala duas pontuações pra cada página web. Uma pontuação se é um hub e outra pontuação se é uma autoridade. Hubs são páginas que linkam pra diversas outras páginas. Pense em um site do Estadão ou da Folha. São hubs de notícia que linkam pra trocentas outras páginas fora. Ou influências como um Nellipfeto que é um hub. Já autoridades são páginas que recebem muitos links de muitos hubs. Pense a página de uma receita federal em época de imposto de renda. Todo mundo faz link pra ela pra avisar que tá vencendo a data ou ensinando com um prensa ou imposto. Mas todo mundo pode ser ao mesmo tempo um hub e uma autoridade. Alguns são mais hub e alguns são mais autoridades num domínio específico e por isso duas pontuações distintas. Portanto o canal de um Nellipfeto da vida teria uma pontuação de hub muito maior do que de autoridade. Que é exatamente o perfil do influencer médio. Serve pra direcionar tráfico pra todo mundo. Mas ele mesmo não é autoridade de quase nada. Na caras como eu geram muito pouco tráfico pros outros mas todo mundo me menciona e linka pra mim em assuntos de um domínio específico de programação e tecnologia. Com isso minha pontuação de autoridade num vídeo sobre algoritmo de Twitter seria maior que do Nellip e eu apareceria no topo da pesquisa mesmo ele tendo muito mais tráfico e sendo muito mais famoso. Essa é a vantagem de algoritmos da família Hitz. Se comparado ao page rank original. Ele torna esse jogo bem mais justo do que uma pontuação única global e tenta melhorar a confusão entre influencer e autoridade. Só porque alguém tem muito seguidor de jeito nenhum o torna autoridade de coisa nenhuma. Porém se antes a forma ingenua era ter uma única pontuação global do page rank em Hitz teríamos sub grafos pra domínio ou tópico. Por exemplo programação gastronomia viagem cinema e cada vértice teria duas pontuações de hub ou autoridade por tópico. Portanto dá pra imaginar que é mais caro computar hits do que page rank. E claro o que temos hoje num Google é uma amálgama dessas técnicas e muitas outras que surgiram ao longo do tempo o que nos leva de volta a salsa.
