Para ilustrar pense nos diferentes algoritmos de ordenação que você aprendeu na faculdade. Alguns professores cometem o pecado de não explicar por que existem tantos e por que foram criados. Por exemplo o meu professor na faculdade mandou a gente decorar lá quicksort mergysort mas não explicou que mergysort foi criado pelo lendário von Neumann por problema de listas de dados que não cabiam na memória RAM da época. Então começavam gravados numa fita. Daí o algoritmo vai percorrendo os elementos da fita sem estourar a RAM e vai gravando ordenado numa segunda fita. Se tiver essa imagem de fitas na cabeça o mergysort finalmente faz sentido. Sem isso é um algoritmo que não faz sentido existir. Em 2012 ainda não existe o equivalente mergysort para grafos que não cabem em memória e precisam ficar divididos em parte de sonhos de hdfs distribuídos em múltiplos servidores. Hoje em dia já existe um suporte maior, pensam a paixa Spark com GraphX. Mas 10 anos atrás era um uso inédito ainda e o próprio paper descreve que eles estavam cientes dessas desvantagens. O paper menciona que o gargalo era na materialização dos vizinhos dos vertos que requeriam um enorme shuffling de dados que é pegar dados de diversos servidores para formar o grafo necessário para o processamento. Nessa parte do paper ele referencia outro paper, o Discovering Similar Users on Twitter, onde é explicado como exatamente eles conseguiram passar as barreiras de usar Hadoop, adaptando o algoritmo de PageRank, personalizado para ambiente distribuído. Como eu já expliquei, esse algoritmo é largamente utilizado para computar similaridade entre nós em um grafo, mas é iterativo e requer data shuffling frequente. Quando eu falo data shuffling, é tipo reembaralhar os dados. Pensa como isso é difícil quando seus dados estão distribuídos em diferentes servidores. Para resolver, os autores do paper propõem uma modificação ao algoritmo de PageRank personalizado chamado OnePass PPR, que reduz o número de iterações e minimiza esse reembaralhamento para cada iteração. Nesse caso, os dados são partitionados e baseados nos aides dos usuários e processados numa única passada sobre os dados usando uma combinação de pontuações local e global. O algoritmo também usa técnicas de caching para evitar recomputar resultados intermediários reduzindo o número de iterações totais. Além disso, os autores também propõem técnicas de compressão para reduzir o tamanho do grafo e possibilitar processamento mais rápido em sistemas distribuídos como Radoop. É muito detalhe para tentar explicar hoje, mas esse é o resumão desse outro paper que também eu recomendo darem uma olhada depois. É nele que se resolve o problema de conseguir dizer que quem segue um LeBron James tem alta probabilidade de seguir um Kobe Bryant, ou quem segue uma Lady Gaga costuma seguir uma Taylor Swift. E é onde nasce o framework que é utilizado até hoje e que eu vou retornar para explicar sobre a arquitetura de geração de candidatos e modelo de aprendizado baseado em regressão logística e similaridade de cosseno para achar usuários similares no Twitter. Voltando ao Castle Very, é só uma parte da solução, é quem dá acesso aos dados dos grafos em Radoop. A solução geral é chamada de realgraph, que é uma representação composta dos grafos de seguidores e grafos de interação induzidos através de logs de comportamento. Essa representação é construída de múltiplos pipelines de funcionalidades que são extraídas, limpas, transformadas e juntadas a partir dos logs screws. O realgraph é armazenado em hds e esse nome realgraph, vamos encontrar no código em escala do repositório que foi liberado, como podemos ver no VS Code. Ainda vez que vê realgraph, provavelmente é isso.
