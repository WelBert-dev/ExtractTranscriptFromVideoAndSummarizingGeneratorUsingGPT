 Mas esse segundo motor de recomendação ainda tinha um grande defeito, só servia para recomendar usuários similares para você seguir e só atualizava poucas vezes ao dia, não era nem perto de ser tempo real. Funcionava, mas ainda não é a aba para você que tem no Twitter hoje. Pulamos do WTF de 2010 para o Castle Very Radoop Realgraph de 2012 e agora saltamos para 2014 e um novo paper que descreve algumas novas estratégias para particionar e organizar esses grafos. Como vocês podem ver, não era um problema trivial de resolver. No caso de Twitter e até em sistemas de mensageria em geral, existe uma particularidade nos dados. Você nunca precisa do grafo inteiro dos usuários. Por exemplo, pouca gente está interessado em ver tweets de mais de um ou dois dias atrás das pessoas que segue. Então mesmo que seja o influencer favorito do Twitter todos os dias, o que seria um volume grande de tweets para o grafo, podemos limitar uma janela de um ou dois dias para todo mundo lidar com um subgrafo muito menor. Pensando assim, não precisamos lidar com operações como deletar um tweet do grafo, por exemplo. Basta pensar em expiração. É mais ou menos o mesmo pensamento por trás de caches como mencash ou redis da vida que usamos hoje. Não pense em como apagar dados velhos, estabeleça uma janela de tempo e deixe expirar sozinho, que é uma boa prática de qualquer tipo de caching. Não só isso, também não precisamos guardar o timestamp exato de cada tweet no grafo. Isso vem da observação que a maioria das interações, como likes, tweets, replies, costumam acontecer muito próximo do momento que o tweet foi criado. Pra maioria de nós é interessante saber que o tweet foi postado uma hora atrás, cinco horas atrás, um dia atrás, mas não exatamente quando. É menos um dado pra ter em memória mais uma economia. Pensando em tudo o que eles aprenderam até agora, iniciariam um terceiro motor de recomendação em cima de outro projeto que eles também tornariam open source, chamado graphjet. Ele mantém um grafo bipartido que registra interações de usuários a tweets durante as mais recentes n horas com uma API super simples só com as operações que eles sabiam que realmente precisam, sem fazer over engine ini de criar um banco de dados de grafos genérico demais. E finalmente tinha uma experiência suficiente pra conseguir especializar a solução. O resto do paper entra em detalhe sobre como foi a estratégia de mapeamento de IDs, estratégia de gerenciamento de memória pra balancear reembaralhamento e distribuição dos dados e em resumo eles conseguiram chegar no modelo onde só o processamento pra encontrar usuários e tweets recomendados ficou na casa abaixo dos 10ms, que é perto do ideal pra conseguir ter resultados em real time, onde a maior parte dos gargáutos era a comunicação com os diversos sistemas de filas, como a paixa e cáfica que eles usam até hoje. Esse paper é bem bacana e eu recomendo ler com muita calma e anotando cada termo que não conhecem pra pesquisar depois, ele descreve as 3 gerações de motores de recomendação dentro do twitter até 2016. Eu não parei pra ver se tem papers mais novos que continuam essa história, mas graças a isso o código liberado que tem vários trechos que mencionam real graph ou graph jet agora deve fazer mais sentido, entendeu? Sem esse tipo de pesquisa só lendo o código liberado ninguém nunca ia entender do que se trata, precisa do contexto histórico. E isso é só a parte do motor de recomendação, existem diversas outras funcionalidades no twitter, por exemplo o motor de pesquisa que é quando você faz pesquisas por palavras chave e ele retorna tweets com esse conteúdo que nem uma pesquisa do google. Na figura da solução do quesa overy que puxa dados do hdfs que vieram no flock db pra cima tem fetchers que mandam pra um serviço chamado blander.
