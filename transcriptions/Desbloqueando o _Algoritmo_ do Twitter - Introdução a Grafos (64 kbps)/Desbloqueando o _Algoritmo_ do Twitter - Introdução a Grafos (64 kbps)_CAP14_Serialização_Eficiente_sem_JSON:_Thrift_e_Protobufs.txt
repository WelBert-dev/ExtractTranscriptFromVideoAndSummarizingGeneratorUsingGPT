 E para terminar essa parte de open source, tem outros dois projetos que são mencionados que eu acho importante explicar. O primeiro se chama thrift, e o segundo é o protocol buffers ou protobuffs. Acho que muitos de vocês já devem ter ouvido falar pelo menos de protobuffs. Bem a grosso modo, pense em microserviços ou endpoints de APIs hoje. A maioria de vocês deve estar acostumado a ter endpoints que se comuniquem ou simplesmente cospem dados em formato JSON. É o Hello World de API em todo tutorial e curso, só que JSON não é a única forma e para muitos casos é a pior opção. JSON é um formato excelente para endpoints de APIs que seres humanos como eu ou você vamos manipular. É indicado para coisas como APIs de e-commerce, onde queremos puxar coisas como principais ofertas para mostrar no nosso blog. Mas para comunicação entre sistemas, por exemplo, o back-end do e-commerce conversar com meios de pagamento ou logística, ou mesmo para comunicação entre microserviços dentro da mesma empresa, é um dos protocolos mais porcaria que existem. Como um exemplo bem, mas bem tosco, imagine esse pequeno JSON de um produto de e-commerce. Quem já trabalhou com e-commerce sabe que é bem maior do que isso, mas para ilustrar aqui no vídeo é suficiente. JSON é um protocolo texto, onde o esquema vai embutido junto com cada registro. Como eu falei, isso facilita para pessoas comuns conseguirem ler sem muita dificuldade. Agora, imagine um esquema de protobuf sendo assim. Note, ele define exatamente que tipo de dados, portanto, qual o tamanho exato de cada campo de dados. Dessa forma, eu não preciso de coisas como aspas, vírgulas, nada disso, eu posso concatenar um valor atrás do outro, porque o tamanho vai ser fixo. E no final, o mesmo JSON convertido em protobuf vai gerar um linguição binário, quem é que essa decimal seria assim? É isso que a nova API com protobuf vai cuspir. Como eu disse antes, ao contrário do JSON, esse formato é 100% hostil para um ser humano conseguir ler. Porém, é 100% perfeito para um computador ler. A fase de converter o JSON numa estrutura de dados é muito mais simples, e um protobuf é muito mais próximo de uma struct de C, só que mais genérico para funcionar em qualquer linguagem. O JSON do exemplo é um string que pesa quase 200 bytes. Já esse linguição que contém exatamente os mesmos dados pesa menos de 80 bytes. Mesmo nesse exemplo supertosco, estamos falando de uma economia de 2.5 vezes na transferência de rede, sem contar a economia de processamento. Lembra que eu falei que o Twitter lida com milhões de tweets todo dia? Imagine se internamente, em todo sistema de pesquisa, bancos de dados distribuídos, sistema de recomendação, filas de processamento, ficasse trafegando tudo em JSON, terabytes e terabytes de bandas sendo desperdiçados. Por isso, o Twitter adotou o equivalente a protobufs do Google, o drift do Facebook. Drift e protobuf é quase a mesma coisa. A única pergunta que você poderia ter é por que o Twitter não usou o protobuf do Google então, em vez de reinventar a roda? E de fato, protobufs foram criados antes, sendo usados dentro do Google desde pelo menos 2001, mas só foi lançado publicamente em 2008 e nesse meio tempo surgiu o Facebook que teve problemas similares para resolver e inventar um drift que lançaram em abril de 2007. Por isso, o Twitter só tinha a opção do drift em 2007. Mas para anar os projetos, especialmente que interagem com componentes como o PyTorch ou o TensorFlow, que também veio do Google, eles passaram a usar protobufs e você vai achar os dois no código. Drift e protobuf são protocolos de serialização de dados. Esse tipo de protocolo é ideal para comunicação entre microserviços, só que diferente de JSON ou XML, a forma de fazer essa comunicação não é via HTTP, como num web service e envia RPC ou Remote Procedure Call, que formaliza como um serviço chama uma função ou procedura de outro serviço. No caso do Google, eles tem o GRPC, que é um framework de RPC que tem como objetivo prover comunicação eficiente e escalável entre serviços na rede. Twitter não usou o GRPC. Finagall é o equivalente de GRPC feito pelo Twitter que usa drift para a serialização de dados em vez de protobufs. Tem os mesmos objetivos de lidar com comunicação de autofruput, baixa latência e na rede. E o Finagall é implementado em cima de net, também usando muita funcionalidade de programação acíncrona com futures de escala, que é o equivalente promises de JavaScript de hoje. Novamente, o Twitter Finagall foi lançado em 2011, o GRPC do Google só sairia por volta de 2015 e o Twitter estava tendo que inventar tecnologias que não existiam ainda e por isso é um case fascinante. Mas claro, Google sendo um nome muito maior e mais reconhecido que Twitter, matou os projetos drift e Finagall. Num projeto moderno você deveria escolher protobufs, GRPC ou alternativas mais modernas. Hoje o drift ainda existe como Apache Drift, mas da Apache temos outras alternativas como Apache Avro, que foi criado mais para o cenário de streaming de dados serializados, ou seja, quando você abre um streaming de um serviço para outro serviço e trafega registros serializados como Avro entre eles. Apache é um nome muito reconhecido para quem é de Java e também no espaço de Data Sciences e Machine Learning. Quem lida com Kafka e é de Java deve ter usado Avro como opção de serialização para jobs em vez de protobufs ou JSON. JSON é mais para linguagens menores, como JavaScript ou mesmo Ruby e PHP. Protobufs são mais usados em soluções que envolvam tecnologias do Google, como em Android, e de qualquer forma vale a pena estudar todas. Então acho que o mundo acaba em JSON ou XML, tem coisa muito melhor e muito mais eficiente que é usado por sistemas realmente de grande volume, para e-commerce da esquina de fato o tanto faz. 
