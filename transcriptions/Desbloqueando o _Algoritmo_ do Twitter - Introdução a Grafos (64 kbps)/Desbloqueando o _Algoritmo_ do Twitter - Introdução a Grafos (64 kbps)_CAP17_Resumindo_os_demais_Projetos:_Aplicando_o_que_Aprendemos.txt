 Sem entrar em muito mais detalhes vamos bater o olho em alguns outros projetos descritos naquele arquivo Rhythm. Veja um aqui chamado Real Graph. Eu falei de Real Graph antes. Veja esse tweet cred que é o algoritmo de PageRank para calcular a reputação dos usuários. Temos esse Reacos Injector que é descrito como o lançador de eventos em Stream para construir os streams de entrada para serviços baseados em GraphJet. Já sabemos o que é GraphJet mas Reacos eu acho que significa recomendações. Então é um Injetor de recomendações para GraphJet. Pulando lá para baixo temos esse Light Ranker que é um ranqueador mais leve usado pelo índice de pesquisa o tal Early Bird que eu mencionei antes que é um projeto legado e parece que ainda é usado o componente construído em cima de a paixa Lucini. O Heavy Ranger está no outro repositório de Algorithm ML que o blog post do Steven que falei lá no começo menciona e segundo o Rhythm é o responsável pela aba para você e tem aquela lista de pesos. Nesse ponto da cadeia depois da fase de Candidate Sourcing temos uns 1500 candidatos que podem ser relevantes. Ponto ação serve para prever a relevância de cada tweet candidato e é o sinal para arranquear tweets na timeline. Nesse estágio todos os candidatos são tratados igualmente e o ranqueamento sai de uma rede neural de uns 48 milhões de parâmetros que é continuamente treinada com interações de tweets para otimizar o engajamento positivo que são likes, replies e tweets segundo o blog de engenharia do Twitter. Sendo bem honesto eu não tenho certeza de como exatamente isso funciona ainda. Olha o diagrama que tem no próprio arquivo Rhythm que lista os projetos. Os dados vêm dessas intituladas grafos social, engajamento de tweets e dados dos usuários. Daí temos features como o GraphJet, SimClusters, Tweet Him que é outro projeto no repositório de Algorithm ML e serve para pré treinar os tais em badgings. Daí temos Real Graph, Tweet Pcred, e Trust and Safety que parece ser um projeto de TensorFlow para treinar modelos para filtrar coisas como conteúdo pornográfico, adulto ou o que ele considera tóxico. Não sabemos exatamente por que não foi liberado o modelo e nem os dados de treino. É um projeto bem pequeno e quem entende de tem o sort flow poderia dizer um pouco mais mas não tem muito para se ver. Continuando temos essa coluna que ele chama de Home Mixer. Daí temos três fases. Um que ele chama de Candidate Sourcing que é literalmente escolher os candidatos, candidatos de recomendação e esses candidatos passam pelo tal Heavy Ranker que parece ser o modelo de Machine Learning via PyTorch. O resultado disso passa pela etapa final de heurísticas e filtros. Então para se chegar nos tweets recomendados na aba para você na etapa de sourcing já acontece diversos filtros para selecionar os candidatos de tweets que você pode gostar de ver. Esses filtros passam pelos projetos de SimCluster, Real Graph, TNS, Tweet Pcred, os GraphJets e são mesclados pelo projeto CR Mixer. Isso vale comentar. Os tweets gerados mais ou menos são metade de tweets gerados pelas pessoas que você segue o que ele chama de In Network e a outra metade de pessoas que você não segue que ele chama de Out of Network. E quem puxa isso é esse projeto CR Mixer. Dado esse conjunto inicial de tweets, In e Out of Network aí vem a parte de recomendação propriamente dita usando o Light Ranker que é o projeto Early Bird e daí o Heavy Ranker. Mas antes de mandar para você ainda passa por um Pipeline de filtros. Pelo projeto Home Mixer propriamente dito, esse Visibility Filters que é onde tá implementado a política de censura do Twitter. E por último tem esse projeto Naave que parece mais recente escrito em Rust mas é super pequeno e não faz muita coisa. Parece mais um adaptador para falar com os componentes de TensorFlow e PyTorch e um tal de Onks que eu não conhecia mas parece que significa Open Neural Network Exchange que é um formato open source para representar modelos de Machine Learning. Foi originalmente desenvolvido pela Microsoft e Facebook em 2017 para facilitar interoperabilidade entre diferentes frameworks de Deep Learning, por exemplo, entre PyTorch e TensorFlow. Mas realmente eu não sei como ele é usado nesse projeto ainda.
